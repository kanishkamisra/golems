---
title: "Statistical Rethinking Week 2 Notes"
author: "Kanishka Misra"
date: "5/7/2019"
output: 
  pdf_document:
    latex_engine: xelatex
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, message = FALSE, warning = FALSE)
library(knitr)
library(rethinking)
library(tidyverse)
extrafont::loadfonts()
set.seed(2791)

data("Howell1")
d <- Howell1

theme_latex <- function() {
  theme(
    text = element_text(family = "CMU Serif"),
    axis.title = element_text(family = "CMU Serif", face = "italic"),
    strip.text = element_text(face = "bold.italic")
  )
}
```

## Gaussian Model for Height

The data in this example are collected from a survey of Kalahari Foragers, collected by Nancy Howell.

```{r}
data("Howell1")
d <- Howell1

precis(d) %>%
  rownames_to_column(var = "variable") %>%
  as_tibble() %>% 
  select(-histogram) %>%
  kable(caption = "Descriptives about the Data")
```

In this example, we look at the height of all adults present in the data. The prior for Height we use is:

\begin{align}
  h_i \sim Normal(\mu, \sigma)
\end{align}

Here, height is observed, while $\mu$ and $\sigma$ are not, and thus have to be inferred from $h_i$. Since it is a bayesian model, we assert their priors as:

\begin{align}
  \mu \sim Normal(178, 20)\\
  \sigma \sim Uniform(0, 50)
\end{align}

We can now simulate from these distributions to check what the model believes prior to seeing the data, this is known as *Prior Predictive Distribution*. This is the best way to check and see what the prior means. This is not *p-hacking* since data is not used. We typically use these models from scientifically available resources. 

```{r fig.height = 2.5, fig.align='center'}
ppd_height <- tibble(
  sample_mu = rnorm(1e4, 178, 20),
  sample_sigma = runif(1e4, 0, 50),
  prior_h = rnorm(1e4, sample_mu, sample_sigma)
)

ppd_height %>%
  gather("variable", "value") %>%
  mutate(
    variable = case_when(
      variable == "prior_h" ~ "h",
      variable == "sample_mu" ~ as.character(bquote(mu)),
      variable == "sample_sigma" ~ as.character(bquote(sigma))
    )
  ) %>%
  ggplot(aes(value, fill = variable, color = variable)) +
  geom_density(alpha = 0.6, show.legend = F) +
  facet_wrap(~variable, scales = "free") +
  theme_latex()
```

While this prior is not very informed, it still lies in the realm of possibility ($h_i$ > 0 cm), however, this prior seems to have a lot of unnaturally tall people. 

### Computing the Posterior Distribution using Grid Approximation

Usually, we never use grid approximation in practical scenarios, but since we only have 2 variables, we do it as follows, for $200 \times 200$ possibilities.

```{r fig.align = 'center', fig.width=4, fig.height=4}
# Subset d for adults
d2 <- d %>%
  filter(age >= 18)

n <- 200

d_grid <- tibble(
  mu = seq(140, 160, length.out = n),
  sigma = seq(4, 9, length.out = n)
) %>% 
  expand(mu, sigma)

compute_grid <- function(mu, sigma, variable) {
  dnorm(variable, mean = mu, sd = sigma, log = T) %>%
    sum()
}

d_grid <- d_grid %>%
  mutate(
    log_likelihood = map2_dbl(mu, sigma, compute_grid, variable = d2$height)
  ) %>%
  mutate(
    prior_mu = dnorm(mu, mean = 178, sd = 20, log = T),
    prior_sigma = dunif(sigma, min = 0, max = 50, log = T),
    product = log_likelihood + prior_mu + prior_sigma,
    prob = exp(product - max(product))
  )

d_grid %>%
  ggplot(aes(x = mu, y = sigma)) +
  geom_raster(aes(fill = prob),
              interpolate = T) +
  # scale_fill_viridis_c() +
  scale_x_continuous(expand = c(0,0), limits = c(130, 165)) +
  scale_y_continuous(expand = c(0,0)) +
  scale_fill_distiller(palette = "YlGnBu", direction = 1) +
  labs(x = expression(mu),
       y = expression(sigma)) +
  coord_cartesian(xlim = range(d_grid$mu),
                  ylim = range(d_grid$sigma)) +
  theme_latex() +
  theme(
    legend.position = "bottom"
  )
```

We now sample from $\mu$ and $\sigma$

### Quadratic Approximation of the Posterior

## Adding a Predictor: Weight


